ğŸŒªï¸ 2026-LLMTornadoSample

A sample reference application demonstrating multimodal AI support workflows using LlmTornado â€” a .NET AI orchestration toolkit.

This project contains example code showing how to use the LlmTornado SDK for advanced AI tasks such as text, speech, image, and multimodal prompt handling using .NET.

âœ… What This Is

This repository provides:

ğŸ“Œ A real .NET sample demonstrating how to invoke multimodal LLM workflows

ğŸ¯ Integration with LlmTornado SDK components (Chat, Audio, Images, Code)

ğŸ“‚ Example usage of text, images, and audio support

ğŸ§ª Reference patterns for building AI-powered features in your own .NET apps

Note: This is a sample project (not a full application) intended for learning and experimentation.

ğŸ“ Included Code

LLMTornadoSample.slnx â€“ .NET solution

LLMTornadoSample.Project/Program.cs â€“ Console sample with multiple multimodal examples

.gitignore

The main code shows how to:

Initialize agents

Load image and audio data

Send multimodal input to the model

Print AI solution output

ğŸš€ Features Demonstrated

âœ” Multimodal support (image + audio + text)
âœ” Integration with the LlmTornado AI SDK
âœ” Streaming response capabilities
âœ” Console output of AI assistant solutions
âœ” Base64 file handling
âœ” Multiple usage patterns (voice memo, screenshots, text prompts)

ğŸ§  Sample Usage

Hereâ€™s an illustrative snippet from the sample app (Program.cs):

var agent = new MultimodalSupportAgent("your-api-key");

byte[] screenshot = await File.ReadAllBytesAsync("error-screenshot.jpg");
byte[] voiceMemo = await File.ReadAllBytesAsync("customer-complaint.mp3");

string solution = await agent.HandleSupportTicket(
    "The application crashes when I click Submit",
    imageData: screenshot,
    audioData: voiceMemo
);

Console.WriteLine(solution);


This shows basic multimodal support using an agent object to process text, images, and voice.

ğŸ“¦ Prerequisites

âœ” .NET SDK installed (version supported by the project)
âœ” API key for your LLM provider (OpenAI, Anthropic, etc.)
âœ” Required dependencies installed via NuGet

Before running the sample, set your API key (example using environment variables):

export YOUR_API_KEY="your_llm_api_key_here"

ğŸ“Œ How to Run the Project

Clone the repository:

git clone https://github.com/gitguy007/2026-LLMTornadoSample.git


Navigate into the project folder:

cd 2026-LLMTornadoSample


Restore and build:

dotnet restore
dotnet build


Run the sample:

dotnet run --project LLMTornadoSample.Project

ğŸ›  Customizing

You can customize the sample to:

Use different LLM models (Azure, OpenAI, Claude, etc.)

Add more multimodal workflows

Integrate external data sources

Build UI or a web API on top of this backend

ğŸ§ª Testing

There are no automated tests included by default. For production projects, add:

Unit tests (e.g., xUnit or NUnit)

Integration tests

Mocking of LLM responses

ğŸ“– Recommended Next Steps

If you want to expand this sample, consider:

âœ… Adding RAG (Retrieval-Augmented Generation) pipelines using vectors
âœ… Building an agentic orchestration layer
âœ… Packaging the logic behind a REST API
âœ… Adding a UI (Blazor / ASP.NET) front end

ğŸ“„ License

This sample is provided under the MIT License (check repository for the full license text if present).

ğŸ§  Acknowledgements

The project uses LlmTornado, a provider-agnostic AI toolkit for .NET.

This sample is intended as a hands-on learning resource.
